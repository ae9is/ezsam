{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ezsam (easy segment anything model)","text":"<p>A command line and gui tool to segment images and video via text prompts.</p> <p>Input images and videos, describe the subjects or objects you want to keep, and output new images and videos with the background removed.</p>"},{"location":"#why","title":"Why?","text":"<p>Meta's Segment Anything is a powerful tool for separating parts of images, but requires coordinate prompts\u2014either bounding boxes or points. And manual prompt generation is tedious for large collections of still images or video.</p> <p>In contrast, text-based prompts describing the object(s) in the foreground to segment can be constant. Inspired by Grounded-Segment-Anything, this project tries to package a simpler to use tool.</p> <p>If you're not interested in text-based prompts with Segment Anything,  check out rembg.</p>"},{"location":"#how-does-it-work","title":"How does it work?","text":"<p>The foreground is selected using text prompts to GroundingDINO to detect objects. Image segments are generated using Segment Anything  or Segment Anything HQ (SAM-HQ).</p>"},{"location":"#_1","title":"About","text":"<p>Get started Learn more</p>"},{"location":"#_2","title":"About","text":""},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v030","title":"v0.3.0","text":"<ul> <li>Add simple gui including binary release</li> <li>Cache models and GroundingDINO config to user cache directory</li> </ul>"},{"location":"changelog/#v021","title":"v0.2.1","text":"<ul> <li>Fix error when no negative prompts detected</li> </ul>"},{"location":"changelog/#v020","title":"v0.2.0","text":"<ul> <li>Add support for negative prompting, i.e. prompting what not to include in the foreground</li> </ul>"},{"location":"changelog/#v010","title":"v0.1.0","text":"<ul> <li>Initial release</li> </ul>"},{"location":"changelog/#_1","title":"Changelog","text":""},{"location":"credits/","title":"Credits","text":"<p>Thanks to all the following projects for providing tools used to build ezsam!</p> <ul> <li>Grounded-Segment-Anything</li> <li>GroundingDINO</li> <li>Segment Anything HQ (SAM-HQ)</li> <li>Segment Anything </li> <li>CustomTkinter</li> <li>PDM</li> <li>Material for MkDocs</li> <li>Nuitka</li> <li>Supervision</li> <li>Numpy</li> <li>Pytorch</li> <li>filetype.py</li> <li>tqdm</li> <li>tkinterdnd2</li> <li>Pillow</li> <li>Ruff</li> </ul>"},{"location":"develop/","title":"Developers","text":""},{"location":"develop/#development","title":"Development","text":"<p>Development is on Python 3.11. To easily switch between versions of python, consider setting up pyenv.</p> <p>This project uses pdm for package management with dependency resolution.</p> <p>Example installation:</p> <pre><code>sudo apt install ffmpeg imagemagick\npip install pipx\npipx install pdm\ngit clone https://github.com/ae9is/ezsam.git\ncd ezsam\npdm install\npdm start\n</code></pre> <p>Note</p> <p>pipx is used to install <code>pdm</code> in a separate environment. This is important for a dependency management program, so that it doesn't break itself! But you might find <code>pdm</code> works just fine via regular <code>pip</code> install.</p> <p>Some environment variables in <code>.env</code> in the project root are set using direnv.</p> <p>Set it up, edit your <code>.env</code> file, and then in project root directory run:</p> <pre><code>direnv allow\n</code></pre> <p>Pre-commit is used for some commit hooks:</p> <pre><code>pip install pre-commit\npre-commit install\n</code></pre>"},{"location":"develop/#operating-system","title":"Operating system","text":"<p>Some dependencies like pytorch install differently depending on your operating system. </p> <p>Currently, the project just installs the default <code>pytorch</code> packages for your system on PyPI. System specific dependencies are excluded from the project's lock file (list of frozen dependencies for reproducible installs).</p> <p>This means Mac and Windows will end up with CPU-targeted versions of pytorch by default, and Linux users will end up with a CUDA 12.1 version of pytorch. The CPU versions of pytorch don't require an NVIDIA GPU, and the dependencies (and built executable) are much smaller, but run much slower.</p> <p>If you're able to, it's highly recommended that you install a CUDA-enabled version of pytorch following the installation matrix here.</p> <p>I.e. on Windows something like (updating version numbers as needed):</p> <pre><code># from github project folder\nsource .venv/bin/activate\npip install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n# or\npdm add https://download.pytorch.org/whl/cu121/torch-2.2.1%2Bcu121-cp311-cp311-win_amd64.whl\npdm add https://download.pytorch.org/whl/cu121/torchvision-0.17.1%2Bcu121-cp311-cp311-win_amd64.whl\n\n</code></pre>"},{"location":"develop/#releases","title":"Releases","text":"<p>Release executables of the GUI are generated using Nuitka.</p>"},{"location":"develop/#standalone-vs-one-file","title":"Standalone vs One-file","text":"<p>In Nuitka, a standalone release refers to a single standalone distributable folder which is then zipped up and delivered to the user to unpack.</p> <p>A one-file release, which also generates a standalone distributable folder, takes the further step of bundling everything up into one executable file.</p> <p>Standalone releases are larger when installed (i.e. unpacked) but start much faster. The one-file executable has to extract itself prior to running, which takes some time given the size of the ezsam machine learning library dependencies.</p>"},{"location":"develop/#local-build","title":"Local build","text":"<p>Install the python requirements for making the releases:</p> <pre><code>pdm install -dG make\n</code></pre> <p>For Nuitka requirements on Linux:</p> <pre><code>sudo apt install gcc ccache patchelf\n</code></pre> <p>See the Nuitka user manual for requirements on other platforms.</p> <p>Then, the run script (which calls a bash script) to make the release is:</p> <pre><code>pdm make-nuitka\n</code></pre> <p>Note</p> <p>You can only generate an executable for the architecture and operating system you're running! I.e. Linux/Windows, arm64/x86_64.</p>"},{"location":"develop/#cloud-build","title":"Cloud build","text":"<p>Multi-platform builds are setup with the GitHub workflow make.yml, which is manually triggered.</p> <p>Warning</p> <p>It's recommended to build a small test program first like tests/nuitka-test-simple.py to make sure the workflow is working correctly. The full ezsam executable build is relatively large and takes a couple hours to build.</p>"},{"location":"develop/#_1","title":"Developers","text":""},{"location":"install/","title":"Installation","text":""},{"location":"install/#requirements","title":"Requirements","text":"<ul> <li>Python 3.9 - 3.11 only </li> <li>FFmpeg </li> <li>ImageMagick </li> <li>(Recommended) Ubuntu 22.04  or Windows 10 </li> </ul>"},{"location":"install/#quick-start","title":"Quick start","text":"<pre><code>pip install ezsam\nsudo apt install ffmpeg imagemagick\nezsam --help\nezsam-gui\n</code></pre>"},{"location":"install/#standard-installation","title":"Standard installation","text":"<pre><code>pip install ezsam\n</code></pre> <p>For video output, you need to install FFmpeg and have it available on your <code>$PATH</code> as <code>ffmpeg</code> for  all the encoding options except GIF.</p> <p>GIF output requires ImageMagick; <code>convert</code> must be available on your <code>$PATH</code>.</p> <pre><code># For apt-based Linuxes like Ubuntu, Debian...\nsudo apt install ffmpeg imagemagick\n</code></pre> <p>If you're having trouble, see Troubleshooting.</p>"},{"location":"install/#binary-installation","title":"Binary installation","text":"<p>The gui app (only) has a compiled executable release.</p> <ol> <li>Still install FFmpeg and/or ImageMagick as in Standard installation</li> <li>(Optional) See here about \"standalone\" vs \"one-file\" releases</li> <li>Download a release</li> <li>Extract anywhere and run</li> </ol> <p>Warning</p> <p>On Windows, you might have to fix the executable's permissions to allow it to run:</p> <ol> <li>Right click release folder or onefile executable \u2192 Properties \u2192 Security \u2192 Advanced</li> <li>Check \"Replace all child object permissions...\", if it's the release folder</li> <li>Select first entry \"Deny Everyone Traverse folder &amp; execute\" \u2192 Remove this Deny permission</li> </ol>"},{"location":"install/#troubleshooting","title":"Troubleshooting","text":""},{"location":"install/#general","title":"General","text":"<p>Thanks to pytorch, and the general state of python package management, you might have run into installation issues.</p> <p>Here's some pointers to try and help:</p> <ul> <li>Setup and use a dedicated version of python that's not your system python, using for example pyenv</li> <li>Use pipx to install in a separate environment: <code>pipx install ezsam</code></li> <li>Try a Development install, which uses locked dependencies in a virtual environment by default</li> </ul> <p>If you really want to get things working:</p> <ul> <li>See if you can run similar tools: rembg, Segment Anything, Grounded Segment Anything</li> <li>Check the project's Issues</li> <li>Use a CUDA 12.1 capable GPU with NVIDIA's official drivers and set <code>$CUDA_HOME</code> </li> <li>Try running the project from an Ubuntu 22.04 install or docker image</li> </ul>"},{"location":"install/#windows","title":"Windows","text":"<p>Just in case it helps.... Here's a list of potential issues Windows 10 users might run into trying to install Python and <code>ezsam</code> from scratch, and one example (non-exhaustive) solution for each:</p> <ol> <li>Installer from <code>python.org</code> can't be executed, even as Administrator. You've already checksummed the installer and checked its permissions.<ul> <li>Workaround: Install Python 3.11 from the Microsoft Store</li> </ul> </li> <li>Microsoft Store Python 3.11 can't create virtual environment (using <code>python -m venv .venv</code>)<ul> <li>Workaround: Don't create virtual environment</li> </ul> </li> <li>Installation (i.e. <code>pip install ezsam</code>) fails without support for long paths<ul> <li>Workaround: https://pip.pypa.io/warnings/enable-long-paths</li> </ul> </li> <li>After installation, <code>ezsam</code> is not on the system PATH<ul> <li>Workaround: Add Microsoft Store python's scripts folder to your user PATH:<ol> <li>Search bar \u2192 <code>Edit the system environment variables</code></li> <li>Click <code>Environment Variables</code></li> <li>User variables for <code>&lt;username&gt;</code> \u2192 Select and edit Path</li> <li>Add new variable, for example (replacing with your user AppData install location):  <code>C:\\Users\\&lt;username&gt;\\AppData\\Local\\Packages\\ PythonSoftwareFoundation.Python.3.11_xxxxxxx\\LocalCache\\local-packages\\Python311\\Scripts</code></li> </ol> </li> </ul> </li> </ol> <p>Your mileage may vary. Good luck!</p>"},{"location":"install/#_1","title":"Installation","text":""},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#gui-app","title":"GUI app","text":"<p>A simple graphical user interface for the command line <code>ezsam</code> tool can be started via:</p> <pre><code>ezsam-gui\n</code></pre> <p>Note</p> <p>The gui can only process a single image or video file at a time, and the output is written to <code>&lt;current_directory&gt;/&lt;input_filename&gt;.out.&lt;output_extension&gt;</code></p>"},{"location":"usage/#options","title":"Options","text":"<p>The command-line app <code>ezsam</code> contains more options than the gui:</p> <pre><code>ezsam --help\n</code></pre>"},{"location":"usage/#examples","title":"Examples","text":"<p>The example images are sourced from rembg for easy comparison.</p>"},{"location":"usage/#simple-image-extraction","title":"Simple image extraction","text":"<p>Process images extracting foreground specified by prompt to <code>examples/animal*.out.png</code>.</p> <pre><code>ezsam examples/animal*.jpg -p animal -o examples\n</code></pre> <p> </p> <p>Note</p> <p>For image extractions, which require adding an alpha channel, the output image format is always <code>png</code>.</p>"},{"location":"usage/#video-filtering","title":"Video filtering","text":"<p>Video files are handled automatically.</p> <pre><code>ezsam car.mkv -p car\n</code></pre> <p>Warning</p> <p>In order to output most of the allowed video formats, FFmpeg needs to be installed and on your <code>$PATH</code>. For GIF output, ImageMagick needs to be installed, with the <code>convert</code> command available. See Installation.</p>"},{"location":"usage/#multiple-subjects","title":"Multiple subjects","text":"<p>Multiple objects can be selected as the foreground. The output image <code>./car-1.out.png</code> contains the car and the person.</p> <pre><code>ezsam examples/car-1.jpg -p car, person\n</code></pre> <p></p>"},{"location":"usage/#debug-mode","title":"Debug mode","text":"<p>Use debug mode to fine tune or troubleshoot prompts. This writes output with foreground mask and object detections annotated over the original image file. Here we write out to <code>test/car-3.debug.jpg</code>.</p> <pre><code>ezsam examples/car-3.jpg -p white car -o test -s .debug --debug\n</code></pre> <p></p> <p>Note</p> <p>Note the original image format <code>jpg</code> is preserved in debug mode!</p>"},{"location":"usage/#object-detection-box-tuning","title":"Object detection box tuning","text":"<p>The object detection box threshold parameter can be used to fine tune objects for selection.</p> <pre><code>ezsam examples/car-3.jpg -p white car -o test --bmin 0.45\n</code></pre> <p></p> <p>Or...</p> <pre><code>ezsam examples/food.mp4 -p turkey -o examples -s .turkey --hq -m vit_h --keep --bmin 0.46\n</code></pre>    A whole cooked turkey flying through the void."},{"location":"usage/#complex-prompts","title":"Complex prompts","text":"<p>Writing prompts with specificity can also help.</p> <pre><code>ezsam examples/anime-girl-2.jpg -o examples -s .debug -p girl, phone, bag, railway crossing sign post --debug\n</code></pre> <p></p> <p>Note</p> <p>When the GroundingDINO object detection model can't map your input prompt onto any classes for a detection box with confidence, in debug mode the generated label for that box will be \"Error\" instead.</p>"},{"location":"usage/#negative-prompting","title":"Negative prompting","text":"<p>Negative (inverse) prompt selections can be used to remove specific objects from selection.</p> <pre><code>ezsam examples/anime-girl-2.jpg -o examples -s .out -p train -n window\n</code></pre> <p></p>"},{"location":"usage/#models","title":"Models","text":"<p>The tool uses GroundingDINO for object detection.</p> <p>To perform image segmentation, you can pick SAM or SAM-HQ:</p> <ul> <li>Segment Anything </li> <li>Segment Anything HQ (SAM-HQ)</li> </ul> <p>For the best results use the biggest model your GPU has memory for. ViT = Vision Transformer, the model type. From best/slowest to worst/fastest: ViT-h(uge) &gt; ViT-l(arge) &gt; ViT-b(ase) &gt; ViT-tiny.</p> <p>Note</p> <p>ViT-tiny is for SAM-HQ only, you must use the <code>--hq</code> flag.</p>"},{"location":"usage/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/#gpu-memory","title":"GPU memory","text":"<p>If you always get an error stating \"CUDA out of memory\", try using a smaller Segment Anything model (vit_tiny, vit_b) or lower resolution (or less) input.</p> <p>If you only get a CUDA OOM error occasionally, or after a while, try to free up some memory by closing processes using the GPU:</p> <pre><code># List commands using nvidia gpu\nfuser -v /dev/nvidia*\n</code></pre> <p>You can also try manually getting the GPU to clear some processes:</p> <pre><code># Clears all processes accounted so far\nsudo nvidia-smi -caa\n</code></pre> <p>If you are using multiple GPUs, and so the GPU you're running CUDA on isn't driving your displays, you can also reset the GPU using:</p> <pre><code># Trigger reset of one or more GPUs\nsudo nvidia-smi -r\n</code></pre> <p>Note</p> <p>nvidia-smi is in the nvidia-utils package of NVIDIA's CUDA repo for Ubuntu.</p>"},{"location":"usage/#gui","title":"GUI","text":""},{"location":"usage/#job-failures","title":"Job failures","text":"<p>On certain job failures the gui might not detect the job as ended, keeping the cursor spinning and preventing another run from being queued. A workaround is to just restart.</p>"},{"location":"usage/#slow-to-load","title":"Slow to load","text":"<p>The one-file build takes a couple seconds to extract itself and start up, see here.</p>"},{"location":"usage/#_1","title":"Usage","text":""}]}