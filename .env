AM_I_DOCKER=False
BUILD_WITH_CUDA=True
CUDA_HOME=/usr/local/cuda
CUDA_VISIBLE_DEVICES=0
# Another option to try and avoid CUDA out of memory issues
# ref: https://pytorch.org/docs/stable/notes/cuda.html#environment-variables
#PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512